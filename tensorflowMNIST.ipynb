{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To implement any no. of hidden layers in Tensorflow.\n",
    "#We will be working on MNIST dataset\n",
    "#You can get the dataset from the link: https://www.kaggle.com/c/digit-recognizer/download/train.csv\n",
    "\n",
    "#First import the basic stuff\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "#Now we will create a function to read the data  and return a normalized numpy matrix\n",
    "def get_data():\n",
    "    df=pd.read_csv(\"train.csv\")\n",
    "    data=df.as_matrix()\n",
    "    X=data[:,1:]\n",
    "    Y=data[:,0]\n",
    "    mean=X.mean(axis=0) #Mean of every col\n",
    "    std=X.std(axis=0) #Standard deviation of every col\n",
    "    #To normalize the data we will use the formula:\n",
    "    #X_normlized=(X-X_mean_along_cols)/(X_standard_dev_along_cols)\n",
    "    #To ensure that we do not encounter a divide by zero exception we replace all standard deviation 0 values with 1\n",
    "    np.place(std,std==0,1)\n",
    "    X=(X-mean)/std\n",
    "    return X,Y\n",
    "\n",
    "X,Y=get_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will split the training data for cross-validation\n",
    "#The last 700 samples will be for testing and the rest of the samples will be for training\n",
    "\n",
    "split=-700\n",
    "Xtrain,Ytrain=X[:split],Y[:split]\n",
    "Xtest,Ytest=X[split:],Y[split:]\n",
    "\n",
    "#We will now convert Ytrain and Ytest as indicator matrices which is similar to one hot encoding\n",
    "Ytrain_ind=pd.get_dummies(Ytrain).as_matrix()\n",
    "Ytest_ind=pd.get_dummies(Ytest).as_matrix()\n",
    "\n",
    "#Lets define all the constant terms we need\n",
    "lr=0.00004 # learning rate\n",
    "no_of_iter=12\n",
    "display_step=20\n",
    "\n",
    "N,D=Xtrain.shape #N is the no. of samples and D is the no. of dimensions or features\n",
    "\n",
    "#We will perform a batch gradient descent with batch size=250\n",
    "\n",
    "batch_size=250\n",
    "n_batches=int(N//batch_size) #no. of batches\n",
    "\n",
    "K=len(set(Ytrain)) #No. of classes,here we have 10 for the digits 0 to 9\n",
    "M1=Xtrain.shape[1] #M1 is now equal to the no. of dimensions i.e. 784\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now coming to the hidden layers,we will have a list that holds the sizes of the hidden layers\n",
    "hls=[100,300] #Hidden Layer sizes.Here we have 2 hidden layers with 100 and 300 nodes\n",
    "\n",
    "#Lets create a  list to store the weights for each layer\n",
    "Wl=[]\n",
    "\n",
    "#We will now create a function that initializes the weights of a single layer as W and b(bias) and returns them as a list\n",
    "def HiddenLayer(M1,M2):\n",
    "    W=np.random.randn(M1,M2)/np.sqrt(M1)\n",
    "    b=np.zeros(M2)\n",
    "    return [W,b]\n",
    "\n",
    "#Lets initialize the weights\n",
    "for M2 in hls:\n",
    "    Wl.append(HiddenLayer(M1,M2))\n",
    "    M1=M2\n",
    "\n",
    "#Final weight layer will be in a seperate list\n",
    "FWl=HiddenLayer(M2,K)\n",
    "\n",
    "#Create tensorflow placeholders for storing the data and the target\n",
    "#It is a must to specify the data type for tensorflow placeholders\n",
    "\n",
    "X=tf.placeholder(tf.float32,shape=(None,D),name='X')\n",
    "T=tf.placeholder(tf.float32,shape=(None,K),name='T')\n",
    "\n",
    "#Forward propagation\n",
    "Xtemp=X\n",
    "for l in Wl:\n",
    "    W=tf.Variable(l[0].astype(np.float32))\n",
    "    b=tf.Variable(l[1].astype(np.float32))\n",
    "    Z=tf.nn.relu(tf.matmul(Xtemp,W)+b) #We are using the ReLu activation function\n",
    "    Xtemp=Z\n",
    "\n",
    "#Finally propagate through the final layer and get the predictions\n",
    "Yish=tf.matmul(Xtemp,FWl[0].astype(np.float32))+FWl[1].astype(np.float32)\n",
    "\n",
    "#Lets define our cost function\n",
    "cost=tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(logits=Yish,labels=T))\n",
    "\n",
    "#Tensorflow will automatically apply our chosen Gradient Descent Optimizer to reduce the cost.\n",
    "#For that lets specify our optimizer\n",
    "train_op=tf.train.RMSPropOptimizer(lr,momentum=0.9).minimize(cost)\n",
    "\n",
    "#Lets predict our outputs\n",
    "predict_op=tf.argmax(Yish,1)\n",
    "\n",
    "#We will create a list to store the costs visualize how the cost is decreasing\n",
    "costs=[]\n",
    "\n",
    "#We need to initialize all variables first\n",
    "init=tf.global_variables_initializer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost / err at iteration i=0, j=0: 1656.572 / 0.883\n",
      "Cost / err at iteration i=0, j=20: 1149.355 / 0.329\n",
      "Cost / err at iteration i=0, j=40: 659.237 / 0.206\n",
      "Cost / err at iteration i=0, j=60: 396.643 / 0.143\n",
      "Cost / err at iteration i=0, j=80: 290.971 / 0.113\n",
      "Cost / err at iteration i=0, j=100: 245.364 / 0.100\n",
      "Cost / err at iteration i=0, j=120: 215.423 / 0.093\n",
      "Cost / err at iteration i=0, j=140: 195.892 / 0.084\n",
      "Cost / err at iteration i=0, j=160: 184.406 / 0.089\n",
      "Cost / err at iteration i=1, j=0: 181.466 / 0.087\n",
      "Cost / err at iteration i=1, j=20: 170.165 / 0.081\n",
      "Cost / err at iteration i=1, j=40: 160.171 / 0.074\n",
      "Cost / err at iteration i=1, j=60: 153.966 / 0.074\n",
      "Cost / err at iteration i=1, j=80: 143.868 / 0.067\n",
      "Cost / err at iteration i=1, j=100: 141.669 / 0.061\n",
      "Cost / err at iteration i=1, j=120: 132.428 / 0.057\n",
      "Cost / err at iteration i=1, j=140: 129.633 / 0.056\n",
      "Cost / err at iteration i=1, j=160: 127.354 / 0.054\n",
      "Cost / err at iteration i=2, j=0: 126.460 / 0.056\n",
      "Cost / err at iteration i=2, j=20: 124.596 / 0.059\n",
      "Cost / err at iteration i=2, j=40: 119.325 / 0.051\n",
      "Cost / err at iteration i=2, j=60: 118.038 / 0.046\n",
      "Cost / err at iteration i=2, j=80: 112.012 / 0.047\n",
      "Cost / err at iteration i=2, j=100: 113.270 / 0.053\n",
      "Cost / err at iteration i=2, j=120: 106.702 / 0.047\n",
      "Cost / err at iteration i=2, j=140: 106.365 / 0.043\n",
      "Cost / err at iteration i=2, j=160: 106.094 / 0.046\n",
      "Cost / err at iteration i=3, j=0: 105.424 / 0.046\n",
      "Cost / err at iteration i=3, j=20: 105.727 / 0.049\n",
      "Cost / err at iteration i=3, j=40: 102.221 / 0.046\n",
      "Cost / err at iteration i=3, j=60: 101.946 / 0.044\n",
      "Cost / err at iteration i=3, j=80: 96.920 / 0.047\n",
      "Cost / err at iteration i=3, j=100: 99.037 / 0.047\n",
      "Cost / err at iteration i=3, j=120: 95.031 / 0.041\n",
      "Cost / err at iteration i=3, j=140: 95.166 / 0.041\n",
      "Cost / err at iteration i=3, j=160: 95.026 / 0.039\n",
      "Cost / err at iteration i=4, j=0: 94.014 / 0.039\n",
      "Cost / err at iteration i=4, j=20: 94.636 / 0.047\n",
      "Cost / err at iteration i=4, j=40: 92.846 / 0.044\n",
      "Cost / err at iteration i=4, j=60: 93.476 / 0.043\n",
      "Cost / err at iteration i=4, j=80: 88.509 / 0.043\n",
      "Cost / err at iteration i=4, j=100: 89.808 / 0.044\n",
      "Cost / err at iteration i=4, j=120: 87.380 / 0.039\n",
      "Cost / err at iteration i=4, j=140: 88.035 / 0.040\n",
      "Cost / err at iteration i=4, j=160: 87.747 / 0.037\n",
      "Cost / err at iteration i=5, j=0: 86.832 / 0.037\n",
      "Cost / err at iteration i=5, j=20: 87.631 / 0.046\n",
      "Cost / err at iteration i=5, j=40: 85.445 / 0.044\n",
      "Cost / err at iteration i=5, j=60: 86.454 / 0.039\n",
      "Cost / err at iteration i=5, j=80: 82.364 / 0.039\n",
      "Cost / err at iteration i=5, j=100: 83.770 / 0.040\n",
      "Cost / err at iteration i=5, j=120: 82.746 / 0.039\n",
      "Cost / err at iteration i=5, j=140: 83.636 / 0.036\n",
      "Cost / err at iteration i=5, j=160: 83.804 / 0.039\n",
      "Cost / err at iteration i=6, j=0: 83.007 / 0.036\n",
      "Cost / err at iteration i=6, j=20: 83.699 / 0.043\n",
      "Cost / err at iteration i=6, j=40: 81.463 / 0.043\n",
      "Cost / err at iteration i=6, j=60: 82.874 / 0.040\n",
      "Cost / err at iteration i=6, j=80: 79.361 / 0.039\n",
      "Cost / err at iteration i=6, j=100: 80.272 / 0.039\n",
      "Cost / err at iteration i=6, j=120: 80.108 / 0.037\n",
      "Cost / err at iteration i=6, j=140: 81.208 / 0.037\n",
      "Cost / err at iteration i=6, j=160: 81.156 / 0.037\n",
      "Cost / err at iteration i=7, j=0: 80.471 / 0.040\n",
      "Cost / err at iteration i=7, j=20: 80.765 / 0.043\n",
      "Cost / err at iteration i=7, j=40: 78.187 / 0.037\n",
      "Cost / err at iteration i=7, j=60: 80.148 / 0.039\n",
      "Cost / err at iteration i=7, j=80: 77.216 / 0.037\n",
      "Cost / err at iteration i=7, j=100: 77.844 / 0.037\n",
      "Cost / err at iteration i=7, j=120: 78.548 / 0.039\n",
      "Cost / err at iteration i=7, j=140: 79.930 / 0.037\n",
      "Cost / err at iteration i=7, j=160: 79.539 / 0.039\n",
      "Cost / err at iteration i=8, j=0: 78.772 / 0.036\n",
      "Cost / err at iteration i=8, j=20: 78.675 / 0.043\n",
      "Cost / err at iteration i=8, j=40: 75.738 / 0.034\n",
      "Cost / err at iteration i=8, j=60: 78.193 / 0.037\n",
      "Cost / err at iteration i=8, j=80: 75.851 / 0.036\n",
      "Cost / err at iteration i=8, j=100: 77.111 / 0.036\n",
      "Cost / err at iteration i=8, j=120: 77.930 / 0.039\n",
      "Cost / err at iteration i=8, j=140: 80.004 / 0.036\n",
      "Cost / err at iteration i=8, j=160: 79.361 / 0.037\n",
      "Cost / err at iteration i=9, j=0: 78.310 / 0.037\n",
      "Cost / err at iteration i=9, j=20: 77.600 / 0.043\n",
      "Cost / err at iteration i=9, j=40: 74.324 / 0.033\n",
      "Cost / err at iteration i=9, j=60: 77.216 / 0.036\n",
      "Cost / err at iteration i=9, j=80: 75.595 / 0.036\n",
      "Cost / err at iteration i=9, j=100: 77.567 / 0.036\n",
      "Cost / err at iteration i=9, j=120: 78.813 / 0.037\n",
      "Cost / err at iteration i=9, j=140: 80.447 / 0.039\n",
      "Cost / err at iteration i=9, j=160: 79.724 / 0.036\n",
      "Cost / err at iteration i=10, j=0: 78.304 / 0.037\n",
      "Cost / err at iteration i=10, j=20: 77.363 / 0.041\n",
      "Cost / err at iteration i=10, j=40: 73.931 / 0.034\n",
      "Cost / err at iteration i=10, j=60: 77.218 / 0.037\n",
      "Cost / err at iteration i=10, j=80: 75.583 / 0.037\n",
      "Cost / err at iteration i=10, j=100: 77.827 / 0.036\n",
      "Cost / err at iteration i=10, j=120: 79.187 / 0.040\n",
      "Cost / err at iteration i=10, j=140: 80.671 / 0.039\n",
      "Cost / err at iteration i=10, j=160: 80.034 / 0.036\n",
      "Cost / err at iteration i=11, j=0: 78.393 / 0.037\n",
      "Cost / err at iteration i=11, j=20: 77.106 / 0.040\n",
      "Cost / err at iteration i=11, j=40: 74.207 / 0.034\n",
      "Cost / err at iteration i=11, j=60: 78.029 / 0.039\n",
      "Cost / err at iteration i=11, j=80: 77.058 / 0.039\n",
      "Cost / err at iteration i=11, j=100: 79.708 / 0.034\n",
      "Cost / err at iteration i=11, j=120: 81.605 / 0.036\n",
      "Cost / err at iteration i=11, j=140: 82.566 / 0.039\n",
      "Cost / err at iteration i=11, j=160: 82.617 / 0.036\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqf8P4d0M4IyxBbAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2eb9fd58518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#We are left with defining one important function i.e. error_rate\n",
    "def error_rate(p,t):\n",
    "    return np.mean(p!=t)\n",
    "\n",
    "\n",
    "#Now lets start the tensorflow session and perform our training and testing process\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init) #To initialize all variables\n",
    "    \n",
    "    for i in range(no_of_iter):\n",
    "        \n",
    "        for j in range(n_batches):\n",
    "            \n",
    "            #Get the training batches\n",
    "            Xbatch=Xtrain[j*batch_size:(j+1)*batch_size]\n",
    "            Ybatch=Ytrain_ind[j*batch_size:(j+1)*batch_size]\n",
    "            \n",
    "            #Lets call the training process\n",
    "            sess.run(train_op,feed_dict={X:Xbatch,T:Ybatch})\n",
    "            \n",
    "            #Lets get the cost , prediction and error rate:\n",
    "            test_cost=sess.run(cost,feed_dict={X:Xtest,T:Ytest_ind})\n",
    "            prediction=sess.run(predict_op,feed_dict={X:Xtest})\n",
    "            \n",
    "            #Every 20 steps we want to see the status of our training\n",
    "            if(j%display_step==0):\n",
    "                err=error_rate(prediction,Ytest)\n",
    "                print (\"Cost / err at iteration i=%d, j=%d: %.3f / %.3f\" % (i, j, test_cost, err))\n",
    "            \n",
    "            #Lets append our test cost to the list of costs we have create\n",
    "            costs.append(test_cost)\n",
    "\n",
    "#Finally after the training is over we want to see the plot of our cost\n",
    "plt.plot(costs)\n",
    "plt.show()\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
